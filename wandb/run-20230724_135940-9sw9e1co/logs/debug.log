2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Configure stats pid to 90553
2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from /Users/heroofwisdom/.config/wandb/settings
2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/settings
2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-07-24 13:59:40,754 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:_log_setup():507] Logging user logs to /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/run-20230724_135940-9sw9e1co/logs/debug.log
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/run-20230724_135940-9sw9e1co/logs/debug-internal.log
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:_jupyter_setup():453] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x172ac4be0>
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:init():547] calling init triggers
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {}
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:init():596] starting backend
2023-07-24 13:59:40,755 INFO    MainThread:90553 [wandb_init.py:init():600] setting up manager
2023-07-24 13:59:40,757 INFO    MainThread:90553 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2023-07-24 13:59:40,758 INFO    MainThread:90553 [wandb_init.py:init():606] backend started and connected
2023-07-24 13:59:40,763 INFO    MainThread:90553 [wandb_run.py:_label_probe_notebook():1233] probe notebook
2023-07-24 13:59:40,764 INFO    MainThread:90553 [wandb_run.py:_label_probe_notebook():1243] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-24 13:59:40,764 INFO    MainThread:90553 [wandb_init.py:init():705] updated telemetry
2023-07-24 13:59:40,806 INFO    MainThread:90553 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
2023-07-24 13:59:41,056 INFO    MainThread:90553 [wandb_run.py:_on_init():2173] communicating current version
2023-07-24 13:59:41,175 INFO    MainThread:90553 [wandb_run.py:_on_init():2182] got version response 
2023-07-24 13:59:41,176 INFO    MainThread:90553 [wandb_init.py:init():789] starting run threads in backend
2023-07-24 13:59:41,246 INFO    MainThread:90553 [wandb_run.py:_console_start():2152] atexit reg
2023-07-24 13:59:41,246 INFO    MainThread:90553 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
2023-07-24 13:59:41,247 INFO    MainThread:90553 [wandb_run.py:_redirect():2072] Wrapping output streams.
2023-07-24 13:59:41,247 INFO    MainThread:90553 [wandb_run.py:_redirect():2097] Redirects installed.
2023-07-24 13:59:41,248 INFO    MainThread:90553 [wandb_init.py:init():830] run started, returning control to user process
2023-07-24 13:59:41,567 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x15f168a30>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172ac5c60>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a0039d50>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 70, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 13:59:48,737 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b8b4f0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172ac5120>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a00850f0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 69, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 13:59:55,585 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0086260>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0085ed0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a00f4df0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 54, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:04,293 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172ba84c0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a00852a0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a01ebfd0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 67, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:09,882 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172a3d240>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b97be0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a007ab30>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 54, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:15,133 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b96ad0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b96350>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x172babf40>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 66, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:20,879 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b82b30>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0136680>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x172bab940>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 61, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:26,501 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172b766e0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0107a60>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a02707f0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 60, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:32,689 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a03be620>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a03bc700>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a03bec80>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 70, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:00:39,606 INFO    MainThread:90553 [wandb_run.py:_finish():1887] finishing run alanfiler/Citrine_Solutions_Engineer_Test_V3/9sw9e1co
2023-07-24 14:00:39,608 INFO    MainThread:90553 [jupyter.py:save_history():445] not saving jupyter history
2023-07-24 14:00:39,608 INFO    MainThread:90553 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-24 14:00:39,608 INFO    MainThread:90553 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-24 14:00:39,608 INFO    MainThread:90553 [wandb_run.py:_atexit_cleanup():2121] got exitcode: 0
2023-07-24 14:00:39,608 INFO    MainThread:90553 [wandb_run.py:_restore():2104] restore
2023-07-24 14:00:39,608 INFO    MainThread:90553 [wandb_run.py:_restore():2110] restore done
2023-07-24 14:00:45,059 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3464] rendering history
2023-07-24 14:00:45,060 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
2023-07-24 14:00:45,067 INFO    MainThread:90553 [wandb_run.py:_footer_sync_info():3423] logging synced files
