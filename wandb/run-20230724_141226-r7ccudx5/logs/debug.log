2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Configure stats pid to 90553
2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from /Users/heroofwisdom/.config/wandb/settings
2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/settings
2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-07-24 14:12:26,554 INFO    MainThread:90553 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-07-24 14:12:26,555 INFO    MainThread:90553 [wandb_init.py:_log_setup():507] Logging user logs to /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/run-20230724_141226-r7ccudx5/logs/debug.log
2023-07-24 14:12:26,555 INFO    MainThread:90553 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/heroofwisdom/Documents/GitHub/Citrine_Test_V3/wandb/run-20230724_141226-r7ccudx5/logs/debug-internal.log
2023-07-24 14:12:26,555 INFO    MainThread:90553 [wandb_init.py:init():547] calling init triggers
2023-07-24 14:12:26,555 INFO    MainThread:90553 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {}
2023-07-24 14:12:26,555 INFO    MainThread:90553 [wandb_init.py:init():571] re-initializing run, found existing run on stack: jkldhq2m
2023-07-24 14:12:26,557 INFO    MainThread:90553 [wandb_run.py:_finish():1887] finishing run alanfiler/Citrine_Solutions_Engineer_Test_V3/jkldhq2m
2023-07-24 14:12:26,557 INFO    MainThread:90553 [jupyter.py:save_history():445] not saving jupyter history
2023-07-24 14:12:26,558 INFO    MainThread:90553 [jupyter.py:save_ipynb():373] not saving jupyter notebook
2023-07-24 14:12:26,558 INFO    MainThread:90553 [wandb_init.py:_jupyter_teardown():435] cleaning up jupyter logic
2023-07-24 14:12:26,558 INFO    MainThread:90553 [wandb_run.py:_atexit_cleanup():2121] got exitcode: 0
2023-07-24 14:12:26,558 INFO    MainThread:90553 [wandb_run.py:_restore():2104] restore
2023-07-24 14:12:26,558 INFO    MainThread:90553 [wandb_run.py:_restore():2110] restore done
2023-07-24 14:12:30,644 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3464] rendering history
2023-07-24 14:12:30,645 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
2023-07-24 14:12:30,651 INFO    MainThread:90553 [wandb_run.py:_footer_sync_info():3423] logging synced files
2023-07-24 14:12:30,755 INFO    MainThread:90553 [wandb_init.py:init():596] starting backend
2023-07-24 14:12:30,756 INFO    MainThread:90553 [wandb_init.py:init():600] setting up manager
2023-07-24 14:12:30,757 INFO    MainThread:90553 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2023-07-24 14:12:30,758 INFO    MainThread:90553 [wandb_init.py:init():606] backend started and connected
2023-07-24 14:12:30,763 INFO    MainThread:90553 [wandb_run.py:_label_probe_notebook():1233] probe notebook
2023-07-24 14:12:30,763 INFO    MainThread:90553 [wandb_run.py:_label_probe_notebook():1243] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-07-24 14:12:30,763 INFO    MainThread:90553 [wandb_init.py:init():705] updated telemetry
2023-07-24 14:12:30,801 INFO    MainThread:90553 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
2023-07-24 14:12:31,869 INFO    MainThread:90553 [wandb_run.py:_on_init():2173] communicating current version
2023-07-24 14:12:31,966 INFO    MainThread:90553 [wandb_run.py:_on_init():2182] got version response 
2023-07-24 14:12:31,966 INFO    MainThread:90553 [wandb_init.py:init():789] starting run threads in backend
2023-07-24 14:12:32,056 INFO    MainThread:90553 [wandb_run.py:_console_start():2152] atexit reg
2023-07-24 14:12:32,057 INFO    MainThread:90553 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
2023-07-24 14:12:32,057 INFO    MainThread:90553 [wandb_run.py:_redirect():2072] Wrapping output streams.
2023-07-24 14:12:32,057 INFO    MainThread:90553 [wandb_run.py:_redirect():2097] Redirects installed.
2023-07-24 14:12:32,058 INFO    MainThread:90553 [wandb_init.py:init():830] run started, returning control to user process
2023-07-24 14:12:32,433 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a05170a0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0517160>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a00f5810>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a00f6b90>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x172a45390>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 70, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:12:38,717 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172600040>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1623fa200>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a01ebca0>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x172a3c370>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x15f58b070>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 69, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:12:45,517 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a001cf40>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0272470>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a01a47c0>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a01a7fa0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1a0078be0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 54, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:12:54,274 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0136dd0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1725c2d40>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1725c2170>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0105c60>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1723ec1f0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 67, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:01,267 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1622e0b50>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x16a038d60>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a05571f0>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x16ad278e0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x172a454b0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 54, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:11,846 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1628a3bb0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1629eb7c0>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1622e0cd0>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a0168550>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x16abec0a0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 66, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:19,624 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1724a12d0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1a00f6cb0>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1623680d0>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x169ed63b0>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x17273f370>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 61, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:26,429 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x15fb16cb0>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1629e63b0>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x15eb0aa70>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x1629e6d40>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x1724a0880>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 60, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:37,708 INFO    MainThread:90553 [wandb_run.py:_config_callback():1281] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.torch_core.trainable_params', 'metrics': [{'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x171cc3490>'}, {'func': 'sklearn.metrics._classification.f1_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x169e3b790>'}, {'func': 'sklearn.metrics._classification.precision_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x169e3bb50>'}, {'func': 'sklearn.metrics._classification.recall_score', 'dim_argmax': -1, 'activation': 'no', 'thresh': None, 'flatten': True, '_name': '<fastai.metrics.AccumMetric object at 0x15ebb8b20>'}], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, '_name': '<fastai.tabular.learner.TabularLearner object at 0x169f56620>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'ParamScheduler': True, 'EarlyStoppingCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': None, 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'n_inp': 2, 'input 1 dim 1': 64, 'input 1 dim 2': 20, 'input 2 dim 1': 64, 'input 2 dim 2': 72, 'batch size': 64, 'batch per epoch': 70, 'model parameters': 62464, 'device': 'cpu', 'frozen': False, 'frozen idx': 0}
2023-07-24 14:13:44,866 INFO    MainThread:90553 [wandb_run.py:_finish():1887] finishing run alanfiler/Citrine_Solutions_Engineer_Test_V3/r7ccudx5
2023-07-24 14:13:44,867 INFO    MainThread:90553 [wandb_run.py:_atexit_cleanup():2121] got exitcode: 0
2023-07-24 14:13:44,867 INFO    MainThread:90553 [wandb_run.py:_restore():2104] restore
2023-07-24 14:13:44,867 INFO    MainThread:90553 [wandb_run.py:_restore():2110] restore done
2023-07-24 14:13:50,340 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3464] rendering history
2023-07-24 14:13:50,342 INFO    MainThread:90553 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
2023-07-24 14:13:50,352 INFO    MainThread:90553 [wandb_run.py:_footer_sync_info():3423] logging synced files
